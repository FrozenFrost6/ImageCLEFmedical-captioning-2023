# -*- coding: utf-8 -*-
"""ImagePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gO7qmIABonV3smi9nWNEDn3tg8ucCUfk
"""

from google.colab import drive
drive.mount("/content/drive")

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
import os

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
tf.test.is_built_with_cuda()
print(tf.version.VERSION)
import sys
sys.version

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import tensorflow as tf
tf.config.list_physical_devices('GPU')
# tf.debugging.set_log_device_placement(False)

base_path = os.getcwd()
print(base_path)

#os.chdir('/content/drive/MyDrive/ImageCLEFmedical-23/weights/testPicturesFeatureVectors/test_densenet121_featureVectors1.csv')

#!unzip /content/drive/MyDrive/ImageCLEFmedical-23/Notebooks/AnveshScripts/trainingResultsMLRG/EnsembleFeatures.zip

# # Load image features data

features1 = pd.read_csv('/content/drive/MyDrive/ImageCLEFmedical-23/weights/testPicturesFeatureVectors/test_densenet121_featureVectors1.csv', header=None)
print(features1)

features2 = pd.read_csv('/content/drive/MyDrive/ImageCLEFmedical-23/weights/testPicturesFeatureVectors/test_densenet169_featureVectors1.csv', header=None)
print(features2)

features3 = pd.read_csv('/content/drive/MyDrive/ImageCLEFmedical-23/weights/testPicturesFeatureVectors/test_densenet201_featureVectors.csv', header=None)
print(features3)

# Merge features data
#features = pd.merge(pd.merge(features1,features2, left_on=0, right_on=0),features3,on=0)
features = pd.merge(pd.merge(features1,features2, left_on=0, right_on=0),features2,on=0)
#features = pd.read_csv(base_path+'/Data/EnsembleWeights/MergedFeatures.csv', header=None)

print(features)

#print(list(features.loc[0])[8194])

#features.to_csv("MergedFeatures.csv")

# Load image labels data
trainLabels = pd.read_csv('/content/drive/MyDrive/ImageCLEFmedical-23/Captioning-Dataset_CLEF-2023/ImageCLEFmedical_Caption_2023_concept_detection_train_labels.csv', sep="\t")
print(trainLabels)

all_cui_train=trainLabels.loc[:,"cuis"]

sep_cui_train=[]
for cui_row in all_cui_train:
  #print(type(cui_row))
  sep_cui_train.extend(cui_row.split(sep=";"))
  
  
print(len(sep_cui_train))
unique_cui_train=np.array(sep_cui_train)
print(len(np.unique(unique_cui_train)))

df_valid = pd.read_csv('/content/drive/MyDrive/ImageCLEFmedical-23/Captioning-Dataset_CLEF-2023/ImageCLEFmedical_Caption_2023_concept_detection_valid_labels.csv', sep="\t")

all_cui_valid=df_valid.loc[:,"cuis"]

sep_cui_valid=[]
for cui_row in all_cui_valid:
  #print(type(cui_row))
  sep_cui_valid.extend(cui_row.split(sep=";"))
  
  
print(len(sep_cui_valid))
unique_cui_valid=np.array(sep_cui_valid)
print(len(np.unique(unique_cui_valid)))

train_and_valid_cuis=[]
train_and_valid_cuis.extend(unique_cui_train)
train_and_valid_cuis.extend(unique_cui_valid)

total_cui=np.array(train_and_valid_cuis)
print("len(np.unique(total_cui))",len(np.unique(total_cui)))
print(total_cui)

from sklearn.preprocessing import LabelEncoder

encoder=LabelEncoder()
encoder.fit(total_cui)
print(len(encoder.classes_))

mlb = MultiLabelBinarizer()
enc_labels=[i for i in range(2125)]
#print(enc_labels)
mlb.fit([enc_labels])

enc_labels = pd.DataFrame([enc_labels])
#print(enc_labels)
#print("Transformed:", mlb.transform([(661,2124,1), (11, 22)]))

encoded_cui_labels = []
print(encoded_cui_labels)
for index, row in trainLabels.iterrows():
    cuisForRow = row["cuis"].split(";")
    encodedRow = encoder.transform(cuisForRow)
    #print(encodedRow)
    encoded_cui_labels.append(mlb.transform([encodedRow])[0].tolist())
    #print((mlb.transform([encodedRow])[0]))















final_features = features.iloc[:, 1:]
print(final_features)

# Train XGBoost model
xgb_model = xgb.XGBClassifier()
xgb_model.load_model('/content/drive/MyDrive/ImageCLEFmedical-23/weights/xgboost_weights/my_model1.model')
predictions = xgb_model.predict(final_features)
print(features)
#xgb_model.fit(X_train, y_train, eval_set=eval_set, eval_metric="logloss", early_stopping_rounds=10)

#print(predictions[301])
predict = np.count_nonzero(predictions[4])
print(predict)
decoded_cui_labels = []
'''
for encoded_row in predictions:
    decoded_row = mlb.inverse_transform(encoded_row)
    decoded_cui_labels.append(decoded_row)
'''
decode = mlb.inverse_transform(predictions)
print(decode[1])
print(np.count_nonzero(decode[4]))


'''
# print the decoded labels
print(decoded_cui_labels)
inverse = mlb.inverse_transform([predictions])
print(inverse)
#print(predict)
i=0
for predict in predictions:
  i+=1
  if i==10:
    break
  #print(predict)
'''

labels = []
for i in decode:
  decoded_labels = encoder.inverse_transform(i)
  labels.append(decoded_labels)
  #decoded_labels = encoder.inverse_transform(decode)
  #print(decoded_labels)
# print the decoded labels

print(labels[4])

#labels is a 2d array - each row contains cuids predicted!

#print(decoded_labels)



